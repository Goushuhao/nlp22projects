## 2022秋 自然语言处理 大作业
----------------
* **胡睿卿**
* **2019200194**
----------------
#### 项目简介
机器学习技术运用于投资领域成为了实证金融学当下的一个大热门话题。当下资产定价中机器学习运用的主流领域是将输入高度结构化的量价数据（如股票历史收益、构建因子等）通过机器学习模型输出选股策略。从本质上来说，这些研究是想从已形成金融资产价格（交易者行为）中通过机器学习挖掘出隐含的规律。本项目另辟蹊径，从投资者情绪出发，通过对股吧中股民发言的情感分析来推测股民的主流情绪进而对未来股价进行预测。

文本的情绪分析是 NLP 中的经典问题。事实也证明，基于预训练模型Bert微调的情感分类器表现是令人满意的。本项目无意在模型上做出重大改变，因此项目中使用的情感分类模型仍然是基于Bert微调。

本项目的一大贡献是提出了一种快速生成较高质量标签的方法。项目初期我们爬取了东方财富网上的海量股吧评论数据。人工打标方法获得一个较大规模的训练集成本过大，因此我们提出了基于分词的朴素贝叶斯分类器的打标方法。方法利用已有的分词器（jieba）和贝叶斯情感分类器（snowNLP），在依赖外界金融知识的情况下启动并将极端正负例加入情感分类器的正负词表迭代模型直至生成一个较大且质量较高的带标签集合。

最终通过抽样检查，我们认为模型的最终效果是能够接受的。

-----------
#### 数据介绍
###### 文本数据
我们从股吧中爬取了千万用户发帖的内容及相关信息。*但是由于数据爬取过程中受到其他老师资助因此数据不便公开*，在此展示一条数据的结构：

``` python
{'stock':600325',
title':<title>华电新庄、老祖说股的父母子女总有一天成为车下鬼 华发股份(600325)股吧 东方财富网股吧</title>',
author':2729094169762236
contents':<div class="stockcodec .xeditor">\r\n华电新庄、老祖说股的父母子女总有一天成为车下鬼<imgsrc="http://gbfek.dfcfw.com/face/emot_default 28x28/emot3.pngtitle="鼓掌"/><img
src="http://gbfek.dfcfw.com/face/emot_default 28x28/emot3.pngtitle="鼓掌"/>\n</div>'
like count':1',
'time': 2017-10-12 03:55:52'
post type':普通贴
'reponse count':4
'view count':3506'}
```
从上至下本别是，股票代码、帖子标题、作者编号、帖子内容、点赞数、发帖时间、帖子类型、回帖数、浏览数。

注意帖子内容中还包含了表情包，在后续处理中我们将表情包作为特殊符号处理加入文本。

###### 停用词表
由于迭代过程中需要进行分词，因此此处需要使用停用词表（src/dataset/hit_stopwords.txt），下载自

###### 分词补充字典
为了将文本中的表情包数据也纳入文本，在数据清洗时，我们将表情包及其 tag 替换为 礐(未出现过的生僻字)+表情包名称。为了防止分词时将其划分开，我们将所有替换后的表情包文本加入自定义词典（src/dataset/user_dict.txt）并赋予其较高的词频以确保 jieba 分词能够识别。

###### 金融正负词表
由于迭代过程中使用的 python 包 SnowNLP 中情感分析的正负词表主要来自电商评论，因此在启动初期可能对金融评论文本存在识别不足的问题，因此我们在启动前就向其正负词表中添加金融中常见的情绪文本（src/dataset/goodw.txt & src/dataset/badw.txt） 

-------
#### 模型介绍
###### 迭代打标
该部分代码主要在 src/scripts/data_cleaning.ipynb

我们使用SnowNLP中自带的情感分类器作为基础模型对帖子进行情感打分。我们认为评分极端高/极端低的有较大把握确为我们要识别的正例/负例。于是我们将其加入SnowNLP的正负词表扩充其词库再对剩下文本进行识别，如此迭代直至我们获得了较高质量的带标签数据。

以上模型中有几处细节：首先，SnowNLP 自带的分词功能较弱，因此我们使用自定义词典补充的 jieba 分词进行替代；其次，表情包也在文本中具有重要情感表达作用，因此我们将表情包进行处理后也加入了文本进行迭代；再次，迭代模型的启动表现较为糟糕，为此我们特别补充了金融领域参加正负词表，并且利用外界金融知识（当日股票涨跌幅较大的相关评论更有可能具有情感偏向性）进行筛选启动。

###### Bert + Fine-tune
该部分代码主要在 src/scripts/FinBERT_SA_Model.py
在通过迭代打标后，我们从62万条的筛选评论中获得了较有把握的6000条带标数据，其中包含了约2500条负例与近3500条正例。此后，我们将其随机划分为训练集和测试集后在Bert微调模型中训练。

Bert预训练模型我们选择的是熵简科技基于中文金融数据构建的FinBERT（https://github.com/valuesimplex/FinBERT）

在Bert基础上我们外接一个全链接层构建了一个二分类器即微调完成。
最终训练结束后，我们在测试机上accuracy 约为 75%。
